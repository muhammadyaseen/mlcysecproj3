{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NzyqehHjUlG"
   },
   "source": [
    "# ML in Cybersecurity: Project III\n",
    "\n",
    "## Team\n",
    "  * **Team name**:  MMM\n",
    "  * **Members**:  Maria Sargsyan (2576831,msargsyan@mpi-inf.mpg.de), Muneeb Aadil (2581794, maadil@mpi-inf.mpg.de), Muhammad Yaseen (2577833, myaseen@mpi-inf.mpg.de).\n",
    "  * **Tutor**: *???*\n",
    "\n",
    "\n",
    "## Logistics\n",
    "  * **Due date**: 12th December 2019, 13:59:59 \n",
    "  * Email the completed notebook to mlcysec_ws1920_staff@lists.cispa.saarland \n",
    "  * Complete this in the previously established **teams of 3**\n",
    "  * Feel free to use the course [mailing list](https://lists.cispa.saarland/listinfo/mlcysec_ws1920_stud) to discuss.\n",
    "  \n",
    "## Timeline\n",
    "  * 28-Nov-2019: Project 3 hand-out\n",
    "  * **12-Dec-2019** (13:59:59): Email completed notebook to mlcysec_ws1920_staff@lists.cispa.saarland\n",
    "\n",
    "  * 19-Dec-2019: Project 3 discussion and summary\n",
    "  \n",
    "  \n",
    "## About this Project\n",
    "In this project, we dive into the vulnerabilities of machine learning models and the difficulties of defending against them. To this end, we require you to implement an evasion attack (craft adversarial examples) yourselves, and defend your own model.   \n",
    "\n",
    "\n",
    "## A Note on Grading\n",
    "The total number of points in this project is 100. We further provide the number of points achievable with each excercise. You should take particular care to document and visualize your results, though.\n",
    "\n",
    "\n",
    " \n",
    "## Filling-in the Notebook\n",
    "You'll be submitting this very notebook that is filled-in with (all!) your code and analysis. Make sure you submit one that has been previously executed in-order. (So that results/graphs are already visible upon opening it). \n",
    "\n",
    "The notebook you submit **should compile** (or should be self-contained and sufficiently commented). Check tutorial 1 on how to set up the Python3 environment.\n",
    "\n",
    "It is extremely important that you **do not** re-order the existing sections. Apart from that, the code blocks that you need to fill-in are given by:\n",
    "```\n",
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#\n",
    "```\n",
    "Feel free to break this into multiple-cells. It's even better if you interleave explanations and code-blocks so that the entire notebook forms a readable \"story\".\n",
    "\n",
    "\n",
    "## Code of Honor\n",
    "We encourage discussing ideas and concepts with other students to help you learn and better understand the course content. However, the work you submit and present **must be original** and demonstrate your effort in solving the presented problems. **We will not tolerate** blatantly using existing solutions (such as from the internet), improper collaboration (e.g., sharing code or experimental data between groups) and plagiarism. If the honor code is not met, no points will be awarded.\n",
    "\n",
    " \n",
    " ## Versions\n",
    "  * v1.0: Initial notebook\n",
    "  * v1.1: Clarifications at 1.1.2, 1.2.2, 2.1\n",
    " \n",
    "  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ewNwfFvbFaR"
   },
   "outputs": [],
   "source": [
    "import time \n",
    " \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import json \n",
    "import time \n",
    "import pickle \n",
    "import sys \n",
    "import csv \n",
    "import os \n",
    "import os.path as osp \n",
    "import shutil \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    " \n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots \n",
    "plt.rcParams['image.interpolation'] = 'nearest' \n",
    "plt.rcParams['image.cmap'] = 'gray' \n",
    " \n",
    "# for auto-reloading external modules \n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "640GrzbOevr0"
   },
   "outputs": [],
   "source": [
    "# Some suggestions of our libraries that might be helpful for this project\n",
    "from collections import Counter          # an even easier way to count\n",
    "from multiprocessing import Pool         # for multiprocessing\n",
    "from tqdm import tqdm                    # fancy progress bars\n",
    "\n",
    "# Load other libraries here.\n",
    "# Keep it minimal! We should be easily able to reproduce your code.\n",
    "# We only support sklearn and pytorch.\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "# We preload pytorch as an example\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJZPEAWYMhYB"
   },
   "outputs": [],
   "source": [
    "compute_mode = 'cpu'\n",
    "\n",
    "if compute_mode == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "elif compute_mode == 'gpu':\n",
    "    # If you are using pytorch on the GPU cluster, you have to manually specify which GPU device to use\n",
    "    # It is extremely important that you *do not* spawn multi-GPU jobs.\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'    # Set device ID here\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    raise ValueError('Unrecognized compute mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxi-lLD0mKHD"
   },
   "source": [
    "#### Helpers\n",
    "\n",
    "In case you choose to have some methods you plan to reuse during the notebook, define them here. This will avoid clutter and keep rest of the notebook succinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBbigqdEmKd8"
   },
   "outputs": [],
   "source": [
    "def identity_func(foo):\n",
    "    return foo\n",
    "\n",
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1pcmKkyjT7y"
   },
   "source": [
    "# 1. Attacking an ML-model\n",
    "\n",
    "In this section, we implement an attack ourselves. We then leverage the Foolbox library to craft adversarial examples. First, however, you need a model you can attack. Feel free to choose the DNN/ConvNN from project 1.\n",
    "\n",
    "Hint: you might want to save the trained model to save time later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaJv_d_Dp7OM"
   },
   "source": [
    "### 1.1.1: Setting up the model (5 Points)\n",
    "\n",
    "Re-use the model from project 1 here and train it until it achieves reasonable accuracy (>92%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1.1: Loading MNIST Data\n",
    "\n",
    "Load and process MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST data\n",
    "BATCH_SIZE = 4\n",
    "VALIDATION_FRACTION = 0.1\n",
    "CLASSES = [str(i) for i in range(0,10)]\n",
    "\n",
    "tsfms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # data loader returns a PIL image, we need to transform it to a Tensor object\n",
    "])\n",
    "\n",
    "# train and test datasets, transformed to a tensor\n",
    "mnist_train_data = torchvision.datasets.MNIST(root=\"./mnist-data/\", download=True, train=True, transform=tsfms)\n",
    "mnist_val_data = torchvision.datasets.MNIST(root=\"./mnist-data/\", download=True, train=True, transform=tsfms)\n",
    "mnist_test_data = torchvision.datasets.MNIST(root=\"./mnist-data/\", download=True, train=False, transform=tsfms)\n",
    "\n",
    "# we need to create a disjoint validation set from within the training set\n",
    "# following the approach taken in this link\n",
    "# https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb\n",
    "\n",
    "num_training = len(mnist_train_data)\n",
    "all_indices = list(range(num_training)) # this gives us indices over the whole training set\n",
    "split = int(np.floor( VALIDATION_FRACTION * num_training))\n",
    "# split indices into disjoint sets\n",
    "train_indices, val_indices = all_indices[split:], all_indices[:split]\n",
    "\n",
    "# now we have the indices for train and val sets, we create a pytorch \n",
    "# custom sampler over both datasets\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# represents a data loader, takes care of random batching and indexing etc.\n",
    "mnist_train_data_loader = torch.utils.data.DataLoader(mnist_train_data, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "mnist_val_data_loader   = torch.utils.data.DataLoader(mnist_val_data, batch_size=BATCH_SIZE, sampler=val_sampler)\n",
    "mnist_test_data_loader  = torch.utils.data.DataLoader(mnist_test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# getting whole data into tensors/arrays \n",
    "# since some sklearn requires matrix instead of torch dataloaders.\n",
    "x_trainval, y_trainval = data_to_arrays(mnist_train_data)\n",
    "x_test, y_test = data_to_arrays(mnist_test_data)\n",
    "print('x_trainval.shape = {},  y_trainval.shape = {}'.format(x_trainval.shape, y_trainval.shape))\n",
    "print('x_test.shape = {},  y_test.shape = {}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1.2: Defining the Model\n",
    "\n",
    "Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model represented as class\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        ## formula to make sure params work out\n",
    "        ## W_out = (W_in - F)/S + 1\n",
    "        ## from http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "        ## we will have 2 conv layers\n",
    "\n",
    "        # in_channel is 1 bcz MNIST is a BW dataset\n",
    "        # from 1 input, we create 6 output feature maps, using 5x5 kernels\n",
    "        # input is 28x28, output will be 24x24\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "\n",
    "        # max pool over the 2x2 region.\n",
    "        # input is 24x24, output will be 12x12 \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # after max pool, out spatial dim is reduced, but num channels coming from \n",
    "        # prev conv1 is still 6. We create 16 feature maps, again using 5x5 kernels\n",
    "        # input is 12x12, output will be 8x8\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        # max pool over the 2x2 region. \n",
    "        # input is 8x8, output will be 4x4\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        ## followed by 2 FC layers, y = Wx + b\n",
    "        # we take features computer after the pool2 step.\n",
    "        # we have 16 maps, each of size 4x4. We will flatten them\n",
    "        self.fc1 = nn.Linear(in_features=16*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "\n",
    "        ## and a last FC layer for predictions\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    # we define the fwd pass, backward pass is automatically defined \n",
    "    # by PyTorch thru lineage\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # flatten\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.tanh(self.fc1(x))\n",
    "        #x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c688qdGtO1v-"
   },
   "outputs": [],
   "source": [
    "# Function to test the model on a give (sub)set.\n",
    "\n",
    "def test_model(cnn_model, is_test_set=False, verbose=False):\n",
    "\n",
    "    class_preds = []\n",
    "    ground_truth = []\n",
    "    incorrect_predictions = []\n",
    "    TEST = is_test_set\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in mnist_test_data_loader if TEST else mnist_val_data_loader:\n",
    "            images, labels = data\n",
    "\n",
    "            # get (unnormalized) predictions\n",
    "            predictions = cnn_model(images)\n",
    "            # normalize to get probability distribution\n",
    "            batch_class_probabilities = [F.softmax(el, dim=0) for el in predictions]\n",
    "            # get index of max value which corresponds to the predicted label\n",
    "            # we discard actual values because they are of no use as we use \n",
    "            # probability dist\n",
    "            _, predicted_labels = torch.max(predictions, 1)\n",
    "\n",
    "            # we save some of the incorrect predictions to view them later for \n",
    "            # insights and reasoning\n",
    "            for i,(t,p) in enumerate(zip(labels.tolist(),predicted_labels.tolist())):\n",
    "                if t != p:\n",
    "                    incorrect_predictions.append(IncorrectPrediction(t,p,images[i],batch_class_probabilities[i]))\n",
    "\n",
    "            ground_truth.append(labels)\n",
    "            #class_probs.append(batch_class_probabilities)\n",
    "            class_preds.append(predicted_labels)\n",
    "\n",
    "    # concat predictions from all batches to get a single vector\n",
    "    test_preds = torch.cat(class_preds)\n",
    "    # actual labels\n",
    "    ground_truth = torch.cat(ground_truth)\n",
    "    # calculate accuracy in percentage given predictions and ground truth\n",
    "    accuracy = get_accuracy_from_predictions(ground_truth, test_preds, verbose=verbose)\n",
    "\n",
    "    return accuracy, incorrect_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1.3: Defining the Loss function, Optimization, and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an instance of CNN model\n",
    "cnn_model = CNNModel()\n",
    "\n",
    "# automatically takes care of one-hot encoding the labels \n",
    "# https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "running_loss = 0.0\n",
    "val_acc_history = []\n",
    "loss_history = []\n",
    "# the training loop\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    for i, data in enumerate(mnist_train_data_loader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            loss_per_1k = running_loss / 1000.0\n",
    "            loss_history.append(loss_per_1k)\n",
    "            \n",
    "            val_acc, _ = test_model(cnn_model, is_test_set=False)\n",
    "            val_acc_history.append(val_acc)\n",
    "            \n",
    "            print(\"Loss: {0} \\t Validation Accuracy: {1}%\".format(str(loss_per_1k), str(val_acc*100)))\n",
    "            \n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize trainset performance\n",
    "\n",
    "# plot loss curve per 1000 batches (per 4000 examples if BS = 4)\n",
    "# Note: we didn't plot it against num_epochs because we didn't run many epochs as network \n",
    "# converges after 1 or 2. We thought it would be more interesting to see trends b/w batches.\n",
    "\n",
    "plt.plot(range(len(loss_history)), loss_history,  \n",
    "         color='g', alpha=0.8, marker='.')\n",
    "plt.gca().set( \n",
    "    xlabel='Batch (x1000)', \n",
    "    ylabel='Loss', \n",
    "    title='Training progress vs. Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot val acc per 1000 batches (per 4000 examples if BS = 4)\n",
    "plt.plot(range(len(val_acc_history)), val_acc_history,  \n",
    "         color='b', alpha=0.8, marker='.')\n",
    "plt.gca().set( \n",
    "    xlabel='Batch (x1000)', \n",
    "    ylabel='Validation Accuracy', \n",
    "    title='Training progress vs. Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1.4: Evaluation\n",
    "\n",
    "Before attacking the model, we need to make sure that it achieves >95% accuracy on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, incorrect_predictions = test_model(loaded_model, is_test_set=True, verbose=False)\n",
    "print('Accuracy on unseen test data is {0}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEQrdyLHsUIu"
   },
   "source": [
    "### 1.1.2: Implementing an attack (15 Points)\n",
    "\n",
    "We now want you to attack the model trained in the previous step. Please implement the FGSM attack mentioned in the lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gcVZnUNbRKOz"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNpI3oUoO1wE"
   },
   "source": [
    "### 1.1.3: adversarial sample set (5 Points)\n",
    "\n",
    "Please additionally generate a dataset containing at least 1,000 adversarial examples using FGSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvYpo9p2O1wF"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ex3qQp3JolD1"
   },
   "source": [
    "### 1.1.3: Visualizing the results (5 Points)\n",
    "\n",
    "Please chose one sample for each class (for example the first when iterating the test data) and plot the (ten) adversarial examples as well as the predicted label (before and after the attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGkp0B0PO1wJ"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPB-GK1CymiV"
   },
   "source": [
    "### 1.2.1: Using libraries for attacks (10 Points)\n",
    "As the field of evasion attacks (in particular for DNN) is very active research field, several libraries have been published that contain attacks. We will work here with the Foolbox (https://github.com/bethgelab/foolbox) library. Please implement two other (recent, advanced) attacks of your choice using this library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa6rPT53LUW8"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#\n",
    "\n",
    "# (a) attack 1\n",
    "# (b) attack 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVH821TOymic"
   },
   "source": [
    "### 1.2.2: Visualizing the results (20 Points)\n",
    "As before, please plot the new adversarial examples. Compare all crafting techniques (FGSM, 2 methods from Foolbox).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69nc8PMRymid"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#\n",
    "\n",
    "# template code (Please feel free to change this)\n",
    "# (each column corresponds to one attack method)\n",
    "col_titles = ['Ori','FGSM','Method 1', 'Method 2'] \n",
    "nsamples = 10\n",
    "nrows = nsamples\n",
    "ncols = len(col_titles)\n",
    "\n",
    "fig, axes = plt.subplots(nrows,ncols,figsize=(8,12))  # create the figure with subplots\n",
    "[ax.set_axis_off() for ax in axes.ravel()]  # remove the axis\n",
    "\n",
    "for ax, col in zip(axes[0], col_titles): # set up the title for each column\n",
    "    ax.set_title(col,fontdict={'fontsize':18,'color':'b'})\n",
    "\n",
    "for i in range(nsamples):\n",
    "    axes[i,0].imshow(images_ori[i])\n",
    "    axes[i,1].imshow(adv_FGSM[i])\n",
    "    axes[i,2].imshow(adv_Method1[i])\n",
    "    axes[i,3].imshow(adv_Method2[i])\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6HxYLl3O1wV"
   },
   "source": [
    "Which differences do you observe when comparing different attack methods? Why?   \n",
    "Please write a brief summary of your findings.   \n",
    "* Does the attack always succeed (the model make wrong prediction on the adversarial sample)?\n",
    "* How different is the adversarial sample from the original image?\n",
    "(L0,L2,Linf norm)  \n",
    "* How about the computation cost of each attack method?\n",
    "* Does the attack require white-box access to the model?\n",
    "* ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJUmrv5Bymij"
   },
   "source": [
    "# 2. Defending an ML model\n",
    "\n",
    "So far, we have focused on attacking an ML model. In this section, we want you to defend your model. As before concerning the attack, you can chose an example from the lecture, or experiment with any idea you have.\n",
    "\n",
    "We do not require the defense to work perfectly - but what we want you to understand is why it works or why it does not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gHUFK6Mymik"
   },
   "source": [
    "### 2.1: Implementing a defense of your choice (25 Points)\n",
    "As stated before, feel free to implement a defense or mitigation of your choice. Evaluate the defense on adversarial examples. This entails at least the 1,000 examples crafted from FGSM.   \n",
    "Also, you are encouraged (optional) to defend against the two other attack methods, i.e. you are free to increase this special test set (for example by >30 examples (>10 from your FGSM attack, >10 from both the two other attacks of the library))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DD0UalSeymim"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#\n",
    "print('Accuracy on adversarial samples (FGSM) %.2f'%acc_FGSM)\n",
    "print('Accuracy on adversarial samples (FGSM) after defense %.2f'%acc_FGSM_defend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sIMRqecuymir"
   },
   "source": [
    "### 2.2: Conclusions (15 Points)\n",
    "Please interpret the results of your defense here. \n",
    "\n",
    "* What did you try to make the classifier more robust against FGSM? \n",
    "* Why did it work? \n",
    "* Is the classifier now robust against FGSM?  \n",
    "* ...\n",
    "\n",
    "Feel free to state any interesting finding you encountered during this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scROCZjDymit"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_3_Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
